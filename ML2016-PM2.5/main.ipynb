{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from numpy.random import permutation\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from sklearn.model_selection import KFold\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(suppress=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize_data cannot get better result\n",
    "def read_data():\n",
    "    features=[]   \n",
    "    print(\"read train data\")\n",
    "    with open ('data/train.csv') as train_csv:\n",
    "        train_csv.readline()\n",
    "        for row in csv.reader(train_csv, delimiter=','):\n",
    "            if row[2] == 'PM2.5':\n",
    "                tmp = row[3:]\n",
    "                features.append(row[3:])             \n",
    "    X_array = np.array(features, dtype=np.float32)  \n",
    "    return X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def read_test_data():\n",
    "    X_train=[]\n",
    "    print(\"read test data\")\n",
    "    with open ('data/test_X.csv') as train_csv:\n",
    "        for row in csv.reader(train_csv, delimiter=','):\n",
    "            if row[1] == 'PM2.5': \n",
    "                tmp = row[2:]         \n",
    "                X_train.append(tmp)        \n",
    "\n",
    "    X_array = np.array(X_train, dtype=np.float32)\n",
    "    ones = np.ones((X_array.shape[0], 1), dtype=np.int32)\n",
    "    X_array = np.append(X_array, ones, axis=1)\n",
    "    return X_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# expand continue hours of continue day into one training data\n",
    "def expand_data(X_array):\n",
    "    #print X_array.shape\n",
    "    x_month = X_array.reshape(12, X_array.shape[0]/12 * X_array.shape[1])\n",
    "    collect_X_train = np.zeros((x_month.shape[0] * (x_month.shape[1]-9),10), dtype=np.float32)\n",
    "    collect_y_train = np.zeros((x_month.shape[0] * (x_month.shape[1]-9) , 1), dtype=np.float32)\n",
    "    \n",
    "    # some raw data value is -1, align it with before hours result\n",
    "    for i in range(x_month.shape[0]):\n",
    "        for j in range (x_month.shape[1]):\n",
    "            if (j>1 and x_month[i,j]<0):\n",
    "                x_month[i,j] = x_month[i,j-1]\n",
    "    #print 'collect_X_train=', collect_X_train.shape\n",
    "    #print 'x_month=', x_month.shape\n",
    "    test=0\n",
    "    for idx in range(x_month.shape[0]):\n",
    "        for i in range(x_month.shape[1]-9):\n",
    "            collect_X_train[test, 0:9] = x_month[idx, i:i+9].ravel()\n",
    "            collect_X_train[test, 9] = 1\n",
    "            collect_y_train[test] = x_month[idx, i+9]\n",
    "            #print collect_X_train[test], collect_y_train[test]\n",
    "            test+=1           \n",
    "    return collect_X_train, collect_y_train\n",
    "\n",
    "#X_data, X_mean, X_scale = read_data()\n",
    "#yyy,  zzz= expand_data(X_data)    \n",
    "#print yyy.shape\n",
    "#print yyy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = read_data()\n",
    "X_train, y_train = expand_data(raw_data)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10000\n",
    "display_step = 2000\n",
    "reg = 0.001\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(tf.float32, [n_samples, n_features])\n",
    "Y = tf.placeholder(tf.float32, [n_samples, 1])\n",
    "\n",
    "# weights\n",
    "W = tf.Variable(tf.zeros([n_features, 1], dtype=np.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1], dtype=np.float32), name=\"bias\")\n",
    "\n",
    "# Construct a linear model\n",
    "pred = tf.add(tf.matmul(X, W), b)\n",
    "\n",
    "regularizer = tf.reduce_sum(tf.square(W)) /(2*n_samples)\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.square(pred-Y))/(2*n_samples)\n",
    "loss = cost + reg * regularizer\n",
    "\n",
    "# Gradient descent\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_weight = []\n",
    "final_bias= []\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(optimizer, feed_dict={X: np.asarray(X_train), Y: np.asarray(y_train)})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(loss, feed_dict={X: np.asarray(X_train), Y: np.asarray(y_train)})\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"loss=\", \"{:.9f}\".format(c)             \n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "    training_loss = sess.run(loss, feed_dict={X: np.asarray(X_train), Y: np.asarray(y_train)})\n",
    "    print \"Training loss=\", training_loss , '\\n'  \n",
    "    final_weight = sess.run(W)\n",
    "    final_bias = sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_predict = read_test_data()\n",
    "import pandas as pd\n",
    "predictions = np.dot(X_predict, final_weight) + final_bias\n",
    "index= []\n",
    "for i in range(len(predictions)):\n",
    "    index.append('id_'+ str(i))  \n",
    "idx_array = np.array(index, dtype=np.str) \n",
    "#print idx_array.shape\n",
    "#print predictions.shape\n",
    "\n",
    "submission = pd.DataFrame({'id' : idx_array, 'value': predictions.flatten()})\n",
    "submission.to_csv('test_result.csv',index=False)\n",
    "# use tensorlfow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use my implementation\n",
    "def cost_func(X, y, weight, reg):\n",
    "    scores =  X.dot(weight) \n",
    "    diff = scores - y\n",
    "    loss =  np.sum(pow(diff, 2))\n",
    "    weight0 = weight\n",
    "    weight0[-1] = 0\n",
    "    regular =  reg * np.sum(weight0 * weight0) \n",
    "    return 0.5 * (loss + regular) / y.shape[0]\n",
    "    \n",
    "def  cost_grad_func(X, y, weight, reg):\n",
    "    num_train = y.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    grad = np.zeros((num_features, 1)) \n",
    "    scores =  X.dot(weight) \n",
    "    diff = scores - y\n",
    "    cost = cost_func(X, y, weight, reg)\n",
    "    weight0 = weight\n",
    "    weight0[-1] = 0\n",
    "    grad = (X.T.dot(diff)+ reg * weight0) / num_train\n",
    "    return cost, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data = read_data()\n",
    "X_train, y_train = expand_data(raw_data)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "learning_rate=0.0001\n",
    "reg=1e-5\n",
    "num_iters=20000\n",
    "batch_size=100\n",
    "loss_history = []\n",
    "test_loss_history = []\n",
    "weight = 0.001 * np.random.randn(n_features, 1).astype(np.float)\n",
    "\n",
    "print \"weight.shape=\", weight.shape\n",
    "print \"X_train.shape=\", X_train.shape\n",
    "\n",
    "# train\n",
    "for it in xrange(num_iters):\n",
    "    X_batch = None\n",
    "    y_batch = None\n",
    "    batch_index = np.random.choice(n_samples, batch_size)\n",
    "    X_batch = X_train[batch_index]\n",
    "    y_batch = y_train[batch_index]\n",
    "    loss, grad = cost_grad_func(X_batch, y_batch, weight, reg)  \n",
    "    weight = weight - learning_rate * grad\n",
    "    if it % 1000 == 0:\n",
    "        print 'iteration %d / %d: loss %f' % (it, num_iters, loss)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history)\n",
    "plt.title('loss_history')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterator')\n",
    "plt.legend(['loss'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_predict = read_test_data()\n",
    "\n",
    "import pandas as pd\n",
    "predictions = np.dot(X_predict, weight)\n",
    "index= []\n",
    "for i in range(len(predictions)):\n",
    "    index.append('id_'+ str(i))  \n",
    "idx_array = np.array(index, dtype=np.str) \n",
    "\n",
    "submission = pd.DataFrame({'id' : idx_array, 'value': predictions.flatten()})\n",
    "submission.to_csv('test_result.csv',index=False)\n",
    "# use my implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
